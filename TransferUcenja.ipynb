{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read only stvari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "states=[\n",
    "    'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut',\n",
    "    'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa',\n",
    "    'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan',\n",
    "    'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire',\n",
    "    'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio',\n",
    "    'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota',\n",
    "    'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia',\n",
    "    'Wisconsin', 'Wyoming'\n",
    "]\n",
    "main_folder=\"..\"\n",
    "trainset=os.path.join(main_folder,'d50States10k')\n",
    "valset=os.path.join(main_folder,'d50States2K_test\\\\test_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definisemo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os \n",
    "import cv2\n",
    "from torch.utils.data import Dataset,TensorDataset\n",
    "\n",
    "def obradi(slika):\n",
    "    r=slika[:,:,0]\n",
    "    g=slika[:,:,1]\n",
    "    b=slika[:,:,2]\n",
    "    slika = np.stack([r, g, b], axis=0)\n",
    "    slika=slika.astype(float)\n",
    "    slika/=255\n",
    "    slika=torch.from_numpy(slika)\n",
    "    return slika"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasa i inicijalizacija seta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LokacijeDataset(Dataset):\n",
    "    def __init__(self,tip):\n",
    "        imena=[] #Ime slike\n",
    "        klase=[] #Broj klase\n",
    "        for i in range(0,50):\n",
    "            \n",
    "            \n",
    "            if tip==\"train\":\n",
    "                put=os.path.join(trainset,states[i])\n",
    "            else:\n",
    "                put=os.path.join(valset,states[i])\n",
    "            slike=os.listdir(put)\n",
    "            N=len(slike)\n",
    "            for j in range(0,N,4):\n",
    "               # print(j,tip)\n",
    "                #print(states[i],slike[j],slike[j][:-7])\n",
    "                imena.append(slike[j][:-6])\n",
    "                klase.append(i)\n",
    "        self.klase=klase\n",
    "        self.imena=imena\n",
    "    def __len__(self):\n",
    "        return len(self.klase)\n",
    "    def __getitem__(self,idx):\n",
    "        ime = self.imena[idx]\n",
    "        klasa = self.klase[idx]\n",
    "        #print(klasa,ime)\n",
    "        ret=[]\n",
    "        for i in range(0,360,90):\n",
    "            #print(ime)\n",
    "            trenime=ime+\"_\"+str(i)+\".jpg\"\n",
    "            put=os.path.join(trainset,states[klasa])\n",
    "            if not os.path.exists(os.path.join(put,trenime)):\n",
    "                put=os.path.join(valset,states[klasa])\n",
    "            put=os.path.join(put,trenime)\n",
    "           # print(put)\n",
    "            slika=cv2.imread(put)\n",
    "            slika=obradi(slika)\n",
    "            ret.append(slika)\n",
    "        del slika\n",
    "        return { \n",
    "            'data':torch.stack(ret),\n",
    "            'label':self.klase[idx]\n",
    "        }\n",
    "\n",
    "train_set = LokacijeDataset(\"train\")\n",
    "train_set,val_set=torch.utils.data.random_split(train_set,[0.9,0.1])\n",
    "test_set= LokacijeDataset(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112500\n",
      "12499\n",
      "24998\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "print(len(val_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=\"cuda\"\n",
    "else:\n",
    "    device=\"cpu\"\n",
    "    print(\"NE RADI CUDA!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicijalizacija mreze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\psiml\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\psiml\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "vgg = models.vgg16_bn(pretrained=True)\n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "class Mreza (nn.Module):\n",
    "    def __init__ (self):\n",
    "        super().__init__()\n",
    "        self.features = deepcopy(vgg.features)\n",
    "        self.avgpool = deepcopy(vgg.avgpool)\n",
    "        self.konvolucija=nn.Sequential(\n",
    "            self.features,\n",
    "            self.avgpool,\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        self.povezan=nn.Sequential(\n",
    "            nn.Linear (100352, 1000),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1000, 450),\n",
    "            nn.BatchNorm1d(450),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(450, 50),\n",
    "        )\n",
    "        self.povezan.to(device)\n",
    "        self.konvolucija.to(device)\n",
    "\n",
    "    def forward (self, x):\n",
    "       # print(x.size())\n",
    "        x=x.type(torch.float)  \n",
    "        a=self.konvolucija(x[:,0,:,:,:])\n",
    "        b=self.konvolucija(x[:,1,:,:,:])\n",
    "        c=self.konvolucija(x[:,2,:,:,:])\n",
    "        d=self.konvolucija(x[:,3,:,:,:])\n",
    "       # print(a,b,c,d)\n",
    "        tens=torch.cat([a,b,c,d],1)\n",
    "        del a,b,c,d\n",
    "        #print(tens)\n",
    "        return self.povezan(tens)\n",
    "model = Mreza()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicijalizacija parametara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "broj_epoha = 50\n",
    "batch_velicina=100\n",
    "loss_funk = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "loader = torch.utils.data.DataLoader(dataset=train_set,batch_size=batch_velicina,shuffle=True,num_workers=0,drop_last=True,pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_set,batch_size=batch_velicina,shuffle=False,num_workers=0,drop_last=False,pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testiranje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def totensor(y):\n",
    "    ret=np.zeros((len(y),50))\n",
    "    for i in range(0,len(y)):\n",
    "        ret[i][round(y[i].item())]=1\n",
    "    ret= torch.Tensor(ret)\n",
    "    ret=ret.to(device)\n",
    "    return ret\n",
    "\n",
    "def test(model,sample):\n",
    "    #print(sample)\n",
    "    sample=sample.to(device)\n",
    "    rez=model(sample.reshape(1,4,3,256,256))\n",
    "    #print(rez)\n",
    "    _,b=torch.max(rez,dim=1)\n",
    "    #print(rez,b)\n",
    "    return b\n",
    "\n",
    "def get_accuracy(y_hat,y):\n",
    "    y_hat = y_hat.cpu().detach().numpy()\n",
    "    y=y.cpu().numpy()\n",
    "    #print(y_hat)\n",
    "    y_hat=np.argmax(y_hat,axis=1)\n",
    "    #print(y_hat)\n",
    "    corrects=(y_hat==y).sum()\n",
    "    #print(y_hat,y,corrects)\n",
    "    return corrects.item()\n",
    "\n",
    "def validation(model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        kol=0\n",
    "        total_loss=0\n",
    "        for batch_num, lokacije in enumerate(val_loader):\n",
    "            x=lokacije['data']\n",
    "            y=lokacije['label']\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "                #print(y)\n",
    "            y_hat = model(x)\n",
    "            loss=loss_funk(y_hat,totensor(y))\n",
    "            total_loss+=loss.detach().item()\n",
    "           # print(np.argmax(y_hat.cpu().detach().numpy(),axis=1),y)\n",
    "            kol+=get_accuracy(y_hat=y_hat, y=y)\n",
    "            #print(kol)\n",
    "            del y_hat\n",
    "        kol=kol*100/len(val_set)\n",
    "        total_loss/=(batch_num+1)\n",
    "    return total_loss,kol\n",
    "\n",
    "def test_weights(net):\n",
    "    print(list(net.parameters())[-6])\n",
    "\n",
    "def test_out():\n",
    "    with torch.no_grad():\n",
    "        a = val_set[100]['data'].reshape(1,4,3,256,256).to(device)\n",
    "        tmp = model(a)\n",
    "    print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treniranje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\t100.00% complete. 3211.04 seconds elapsed in epoch. Time until completion 0.00 seconds...\n",
      "NEW BEST MODEL: Epoch: 1 | Train Loss: 2.8684 | Train Accuracy: 21.26 | Validation Loss: 2.4053 | Validation Accuracy: 32.26\n",
      "Epoch: 2\t100.00% complete. 2413.75 seconds elapsed in epoch. Time until completion 0.00 seconds...\n",
      "NEW BEST MODEL: Epoch: 2 | Train Loss: 2.2351 | Train Accuracy: 35.82 | Validation Loss: 2.2493 | Validation Accuracy: 36.52\n",
      "Epoch: 3\t100.00% complete. 2493.48 seconds elapsed in epoch. Time until completion 0.00 seconds...\n",
      "NEW BEST MODEL: Epoch: 3 | Train Loss: 1.8175 | Train Accuracy: 46.60 | Validation Loss: 2.2384 | Validation Accuracy: 37.14\n",
      "Epoch: 4\t100.00% complete. 2453.31 seconds elapsed in epoch. Time until completion 0.00 seconds...\n",
      "NEW BEST MODEL: Epoch: 4 | Train Loss: 1.4418 | Train Accuracy: 56.39 | Validation Loss: 2.2778 | Validation Accuracy: 37.42\n",
      "Epoch: 5\t100.00% complete. 2528.42 seconds elapsed in epoch. Time until completion 0.00 seconds...\n",
      "Epoch: 5 | Train Loss: 1.1092 | Train Accuracy: 65.76 | Validation Loss: 2.4195 | Validation Accuracy: 36.81\n",
      "Epoch: 6\t100.00% complete. 2446.15 seconds elapsed in epoch. Time until completion 0.00 seconds...\n",
      "Epoch: 6 | Train Loss: 0.8443 | Train Accuracy: 73.40 | Validation Loss: 2.5908 | Validation Accuracy: 36.42\n",
      "Epoch: 7\t100.00% complete. 2472.56 seconds elapsed in epoch. Time until completion 0.00 seconds...\n",
      "Epoch: 7 | Train Loss: 0.6600 | Train Accuracy: 78.99 | Validation Loss: 2.6970 | Validation Accuracy: 36.34\n",
      "Epoch: 8\t32.62% complete. 794.86 seconds elapsed in epoch. Time until completion 1641.69 seconds.\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     18\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> 19\u001b[0m \u001b[39mfor\u001b[39;00m batch_num, lokacije \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(loader):\n\u001b[0;32m     20\u001b[0m         \u001b[39m#test_out()\u001b[39;00m\n\u001b[0;32m     21\u001b[0m        \u001b[39m# print(\"RADI\")\u001b[39;00m\n\u001b[0;32m     22\u001b[0m         x\u001b[39m=\u001b[39mlokacije[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     23\u001b[0m         y\u001b[39m=\u001b[39mlokacije[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\psiml\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\psiml\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\psiml\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\psiml\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\psiml\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[1;32m--> 298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "Cell \u001b[1;32mIn[3], line 36\u001b[0m, in \u001b[0;36mLokacijeDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     34\u001b[0m  put\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(put,trenime)\n\u001b[0;32m     35\u001b[0m \u001b[39m# print(put)\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m  slika\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39;49mimread(put)\n\u001b[0;32m     37\u001b[0m  slika\u001b[39m=\u001b[39mobradi(slika)\n\u001b[0;32m     38\u001b[0m  ret\u001b[39m.\u001b[39mappend(slika)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model = model\n",
    "best_acc=0\n",
    "\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import datetime\n",
    "ime=\"TrainingLogs\\\\VGG_TRAINING_\"\n",
    "ime+=datetime.datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "ime+=\".txt\"\n",
    "#print(ime)\n",
    "ouf = open(ime,\"w\")  \n",
    "for epoha in range(1,broj_epoha+1):\n",
    "    train_running_loss =0.0\n",
    "    train_acc=0.0\n",
    "    model = model.train()\n",
    "    \n",
    "    start = time.time()\n",
    "    for batch_num, lokacije in enumerate(loader):\n",
    "            #test_out()\n",
    "           # print(\"RADI\")\n",
    "            x=lokacije['data']\n",
    "            y=lokacije['label']\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "           # print(x)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x)\n",
    "            #print(y_hat.get_device())\n",
    "            #print(y.get_device())\n",
    "           # print(y_hat,totensor(y))\n",
    "            loss = loss_funk(y_hat, totensor(y))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            train_running_loss += loss.detach().item()\n",
    "            train_acc += get_accuracy(y_hat=y_hat, y=y)\n",
    "            del y_hat\n",
    "            del x\n",
    "            del y \n",
    "            del loss\n",
    "\n",
    "            print(f'Epoch: {epoha}\\t{100 * (batch_num + 1) / len(loader):.2f}% complete. {time.time() - start:.2f} seconds elapsed in epoch. Time until completion {(time.time()-start)/((batch_num + 1) / len(loader)) - time.time()+start:.2f} seconds.',\n",
    "                end='\\r')\n",
    "\n",
    "    print(f'',end='\\n')    \n",
    "    epoch_loss = train_running_loss / (batch_num+1)\n",
    "    epoch_acc = 100*train_acc / ((batch_num+1)*batch_velicina)\n",
    "    val_loss,val_acc = validation(model)\n",
    "    if val_acc>best_acc:\n",
    "        best_acc=val_acc\n",
    "        best_model=copy.deepcopy(model)\n",
    "        torch.save(best_model,'VGGBestModel.pt')\n",
    "        ouf.write(\"NEW BEST MODEL: \")\n",
    "        print(\"NEW BEST MODEL: \",end='')\n",
    "\n",
    "    ouf.write('Epoch: %d | Train Loss: %.4f | Train Accuracy: %.2f | Validation Loss: %.4f | Validation Accuracy: %.2f' \\\n",
    "          %(epoha, epoch_loss, epoch_acc,val_loss,val_acc))\n",
    "    ouf.write(\"\\n\")\n",
    "    print('Epoch: %d | Train Loss: %.4f | Train Accuracy: %.2f | Validation Loss: %.4f | Validation Accuracy: %.2f' \\\n",
    "          %(epoha, epoch_loss, epoch_acc,val_loss,val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(val_set)):\n",
    "    a=val_set[i]['data']\n",
    "    if(test(model,a)==val_set[i]['label']):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        kol=0\n",
    "        total_loss=0\n",
    "        for batch_num, lokacije in enumerate(val_loader):\n",
    "            x=lokacije['data']\n",
    "            y=lokacije['label']\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "                #print(y)\n",
    "            y_hat = model(x)\n",
    "            loss=loss_funk(y_hat,totensor(y))\n",
    "            total_loss+=loss.detach().item()\n",
    "           # print(np.argmax(y_hat.cpu().detach().numpy(),axis=1),y)\n",
    "            kol+=get_accuracy(y_hat=y_hat, y=y)/len(y)\n",
    "            #print(kol)\n",
    "            del y_hat\n",
    "        print(batch_num)\n",
    "        kol=kol*100/(batch_num+1)\n",
    "        #total_loss/=(batch_num+1)\n",
    "    return total_loss,kol\n",
    "\n",
    "validation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(dataset=val_set,batch_size=500,shuffle=False,num_workers=0,drop_last=False,pin_memory=True)\n",
    "\n",
    "def get_accuracy(y_hat,y):\n",
    "    y_hat = y_hat.cpu().detach().numpy()\n",
    "    y=y.cpu().numpy()\n",
    "    #print(y_hat)\n",
    "    y_hat=np.argmax(y_hat,axis=1)\n",
    "    #print(y_hat)\n",
    "    corrects=(y_hat==y).sum()\n",
    "    #print(y_hat,y,corrects)\n",
    "    return corrects.item()\n",
    "\n",
    "def vall(model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        kol=0\n",
    "        for batch_num, lokacije in enumerate(val_loader):\n",
    "            x=lokacije['data']\n",
    "            y=lokacije['label']\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "                #print(y)\n",
    "            #print(x.size())\n",
    "            y_hat = model(x)\n",
    "            #print(y_hat)\n",
    "            #print(y_hat,y)\n",
    "            kol+=get_accuracy(y_hat=y_hat, y=y)\n",
    "            del y_hat\n",
    "    return kol\n",
    "\n",
    "vall(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.277770133972168, 37.41899351948156)\n"
     ]
    }
   ],
   "source": [
    "print(validation(best_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model,'VGGBestModel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = torch.load('VGGBestModel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9  8 23 ...  2 42 43] [ 0  0  0 ... 49 49 49]\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_set,batch_size=batch_velicina,shuffle=False,num_workers=0,drop_last=False,pin_memory=True)\n",
    "\n",
    "\n",
    "gmatrix = []\n",
    "labele=[]\n",
    "for batch_num, lokacije in enumerate(test_loader):\n",
    "    x=lokacije['data']\n",
    "    y=lokacije['label']\n",
    "    x = x.to(device)\n",
    "    for i in range(1,len(y)):\n",
    "        labele.append(y[i].cpu().detach().numpy())\n",
    "    y_hat = best_model(x)\n",
    "    y_hat= y_hat.cpu().detach().numpy()\n",
    "    y_hat=np.argmax(y_hat,axis=1)\n",
    "    for i in range(0,len(y_hat)):\n",
    "       gmatrix.append(y_hat[i])\n",
    "    #print(gmatrix)\n",
    "gmatrix=np.array(gmatrix)\n",
    "labele=np.array(labele)\n",
    "print(gmatrix,labele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24748 24998 24998\n",
      "24998 24998 24998\n",
      "7572\n"
     ]
    }
   ],
   "source": [
    "print(len(labele),len(gmatrix),len(test_set))\n",
    "for i in range(len(labele),len(gmatrix)):\n",
    "    labele=np.append(labele,49)\n",
    "print(len(labele),len(gmatrix),len(test_set))\n",
    "kol=0\n",
    "for i in range(1,len(gmatrix)):\n",
    "    if gmatrix[i]==labele[i]:\n",
    "        kol+=1\n",
    "print(kol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouf = open(\"VGGRezultati.txt\",\"w\")\n",
    "for i in range(1,len(gmatrix)):\n",
    "    ouf.write(str(round(gmatrix[i]))+\" \"+str(labele[i])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(labele, gmatrix)\n",
    "\n",
    "for i in range(0, 50):\n",
    "    p = np.sum(cf_matrix[i])\n",
    "    cf_matrix[i] = cf_matrix[i] * 100 / p\n",
    "\n",
    "plt.figure(figsize=(80, 45))\n",
    "sns.heatmap(cf_matrix/100, annot=True, fmt='.2%', cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
