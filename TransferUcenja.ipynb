{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read only stvari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "states=[\n",
    "    'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut',\n",
    "    'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa',\n",
    "    'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan',\n",
    "    'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire',\n",
    "    'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio',\n",
    "    'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota',\n",
    "    'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia',\n",
    "    'Wisconsin', 'Wyoming'\n",
    "]\n",
    "main_folder=\"..\"\n",
    "trainset=os.path.join(main_folder,'d50States10k')\n",
    "valset=os.path.join(main_folder,'d50States2K_test\\\\test_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definisemo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os \n",
    "import cv2\n",
    "from torch.utils.data import Dataset,TensorDataset\n",
    "\n",
    "def obradi(slika):\n",
    "    r=slika[:,:,0]\n",
    "    g=slika[:,:,1]\n",
    "    b=slika[:,:,2]\n",
    "    slika = np.stack([r, g, b], axis=0)\n",
    "    slika=slika.astype(float)\n",
    "    slika/=255\n",
    "    slika=torch.from_numpy(slika)\n",
    "    return slika"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasa i inicijalizacija seta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LokacijeDataset(Dataset):\n",
    "    def __init__(self,tip):\n",
    "        imena=[] #Ime slike\n",
    "        klase=[] #Broj klase\n",
    "        for i in range(0,50):\n",
    "            \n",
    "            \n",
    "            if tip==\"train\":\n",
    "                put=os.path.join(trainset,states[i])\n",
    "            else:\n",
    "                put=os.path.join(valset,states[i])\n",
    "            slike=os.listdir(put)\n",
    "            N=len(slike)\n",
    "            for j in range(0,N,4):\n",
    "               # print(j,tip)\n",
    "                #print(states[i],slike[j],slike[j][:-7])\n",
    "                imena.append(slike[j][:-6])\n",
    "                klase.append(i)\n",
    "        self.klase=klase\n",
    "        self.imena=imena\n",
    "    def __len__(self):\n",
    "        return len(self.klase)\n",
    "    def __getitem__(self,idx):\n",
    "        ime = self.imena[idx]\n",
    "        klasa = self.klase[idx]\n",
    "        #print(klasa,ime)\n",
    "        ret=[]\n",
    "        for i in range(0,360,90):\n",
    "            #print(ime)\n",
    "            trenime=ime+\"_\"+str(i)+\".jpg\"\n",
    "            put=os.path.join(trainset,states[klasa])\n",
    "            if not os.path.exists(os.path.join(put,trenime)):\n",
    "                put=os.path.join(valset,states[klasa])\n",
    "            put=os.path.join(put,trenime)\n",
    "           # print(put)\n",
    "            slika=cv2.imread(put)\n",
    "            slika=obradi(slika)\n",
    "            ret.append(slika)\n",
    "        del slika\n",
    "        return { \n",
    "            'data':torch.stack(ret),\n",
    "            'label':self.klase[idx]\n",
    "        }\n",
    "\n",
    "train_set = LokacijeDataset(\"train\")\n",
    "train_set,val_set=torch.utils.data.random_split(train_set,[0.9,0.1])\n",
    "test_set= LokacijeDataset(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112500\n",
      "12499\n",
      "24998\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "print(len(val_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=\"cuda\"\n",
    "else:\n",
    "    device=\"cpu\"\n",
    "    print(\"NE RADI CUDA!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicijalizacija mreze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\psiml\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\psiml\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "vgg = models.vgg16_bn(pretrained=True)\n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "class Mreza (nn.Module):\n",
    "    def __init__ (self):\n",
    "        super().__init__()\n",
    "        self.features = deepcopy(vgg.features)\n",
    "        self.avgpool = deepcopy(vgg.avgpool)\n",
    "        self.konvolucija=nn.Sequential(\n",
    "            self.features,\n",
    "            self.avgpool,\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        self.povezan=nn.Sequential(\n",
    "            nn.Linear (100352, 1000),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1000, 450),\n",
    "            nn.BatchNorm1d(450),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(450, 50),\n",
    "        )\n",
    "        self.povezan.to(device)\n",
    "        self.konvolucija.to(device)\n",
    "\n",
    "    def forward (self, x):\n",
    "       # print(x.size())\n",
    "        x=x.type(torch.float)  \n",
    "        a=self.konvolucija(x[:,0,:,:,:])\n",
    "        b=self.konvolucija(x[:,1,:,:,:])\n",
    "        c=self.konvolucija(x[:,2,:,:,:])\n",
    "        d=self.konvolucija(x[:,3,:,:,:])\n",
    "       # print(a,b,c,d)\n",
    "        tens=torch.cat([a,b,c,d],1)\n",
    "        del a,b,c,d\n",
    "        #print(tens)\n",
    "        return self.povezan(tens)\n",
    "model = Mreza()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicijalizacija parametara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "broj_epoha = 50\n",
    "batch_velicina=100\n",
    "loss_funk = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "loader = torch.utils.data.DataLoader(dataset=train_set,batch_size=batch_velicina,shuffle=True,num_workers=0,drop_last=True,pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_set,batch_size=batch_velicina,shuffle=False,num_workers=0,drop_last=False,pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testiranje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def totensor(y):\n",
    "    ret=np.zeros((len(y),50))\n",
    "    for i in range(0,len(y)):\n",
    "        ret[i][round(y[i].item())]=1\n",
    "    ret= torch.Tensor(ret)\n",
    "    ret=ret.to(device)\n",
    "    return ret\n",
    "\n",
    "def test(model,sample):\n",
    "    #print(sample)\n",
    "    sample=sample.to(device)\n",
    "    rez=model(sample.reshape(1,4,3,256,256))\n",
    "    #print(rez)\n",
    "    _,b=torch.max(rez,dim=1)\n",
    "    #print(rez,b)\n",
    "    return b\n",
    "\n",
    "def get_accuracy(y_hat,y):\n",
    "    y_hat = y_hat.cpu().detach().numpy()\n",
    "    y=y.cpu().numpy()\n",
    "    #print(y_hat)\n",
    "    y_hat=np.argmax(y_hat,axis=1)\n",
    "    #print(y_hat)\n",
    "    corrects=(y_hat==y).sum()\n",
    "    #print(y_hat,y,corrects)\n",
    "    return corrects.item()\n",
    "\n",
    "def validation(model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        kol=0\n",
    "        total_loss=0\n",
    "        for batch_num, lokacije in enumerate(val_loader):\n",
    "            x=lokacije['data']\n",
    "            y=lokacije['label']\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "                #print(y)\n",
    "            y_hat = model(x)\n",
    "            loss=loss_funk(y_hat,totensor(y))\n",
    "            total_loss+=loss.detach().item()\n",
    "           # print(np.argmax(y_hat.cpu().detach().numpy(),axis=1),y)\n",
    "            kol+=get_accuracy(y_hat=y_hat, y=y)\n",
    "            #print(kol)\n",
    "            del y_hat\n",
    "        kol=kol*100/len(val_set)\n",
    "        total_loss/=(batch_num+1)\n",
    "    return total_loss,kol\n",
    "\n",
    "def test_weights(net):\n",
    "    print(list(net.parameters())[-6])\n",
    "\n",
    "def test_out():\n",
    "    with torch.no_grad():\n",
    "        a = val_set[100]['data'].reshape(1,4,3,256,256).to(device)\n",
    "        tmp = model(a)\n",
    "    print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treniranje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\t100.00% complete. 4232.38 seconds elapsed in epoch. Time until completion 0.00 seconds...\n",
      "NEW BEST MODEL: Epoch: 1 | Train Loss: 2.8703 | Train Accuracy: 21.50 | Validation Loss: 2.3877 | Validation Accuracy: 32.19\n",
      "Epoch: 2\t100.00% complete. 2469.64 seconds elapsed in epoch. Time until completion 0.00 seconds...\n",
      "NEW BEST MODEL: Epoch: 2 | Train Loss: 2.2295 | Train Accuracy: 35.94 | Validation Loss: 2.2504 | Validation Accuracy: 35.43\n",
      "Epoch: 3\t100.00% complete. 2492.16 seconds elapsed in epoch. Time until completion 0.00 seconds...\n",
      "NEW BEST MODEL: Epoch: 3 | Train Loss: 1.8150 | Train Accuracy: 46.56 | Validation Loss: 2.2125 | Validation Accuracy: 36.63\n",
      "Epoch: 4\t100.00% complete. 2478.67 seconds elapsed in epoch. Time until completion 0.00 seconds...\n",
      "NEW BEST MODEL: Epoch: 4 | Train Loss: 1.4422 | Train Accuracy: 56.47 | Validation Loss: 2.2713 | Validation Accuracy: 37.07\n",
      "Epoch: 5\t100.00% complete. 2467.38 seconds elapsed in epoch. Time until completion 0.00 seconds...\n",
      "Epoch: 5 | Train Loss: 1.1143 | Train Accuracy: 65.78 | Validation Loss: 2.4036 | Validation Accuracy: 36.85\n",
      "Epoch: 6\t100.00% complete. 2507.09 seconds elapsed in epoch. Time until completion 0.00 seconds...\n",
      "Epoch: 6 | Train Loss: 0.8511 | Train Accuracy: 73.37 | Validation Loss: 2.5349 | Validation Accuracy: 36.40\n",
      "Epoch: 7\t100.00% complete. 2451.50 seconds elapsed in epoch. Time until completion 0.00 seconds...\n",
      "Epoch: 7 | Train Loss: 0.6559 | Train Accuracy: 79.17 | Validation Loss: 2.6837 | Validation Accuracy: 36.43\n",
      "Epoch: 8\t100.00% complete. 2463.27 seconds elapsed in epoch. Time until completion 0.00 seconds...\n",
      "Epoch: 8 | Train Loss: 0.5335 | Train Accuracy: 83.00 | Validation Loss: 2.8030 | Validation Accuracy: 35.92\n",
      "Epoch: 9\t100.00% complete. 2463.19 seconds elapsed in epoch. Time until completion 0.00 seconds...\n",
      "Epoch: 9 | Train Loss: 0.4553 | Train Accuracy: 85.36 | Validation Loss: 2.9248 | Validation Accuracy: 35.90\n",
      "Epoch: 10\t100.00% complete. 2706.97 seconds elapsed in epoch. Time until completion 0.00 seconds...\n"
     ]
    }
   ],
   "source": [
    "best_model = model\n",
    "best_acc=0\n",
    "\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import datetime\n",
    "ime=\"TrainingLogs\\\\VGG_TRAINING_\"\n",
    "ime+=datetime.datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "ime+=\".txt\"\n",
    "#print(ime)\n",
    "ouf = open(ime,\"w\")  \n",
    "for epoha in range(1,broj_epoha+1):\n",
    "    train_running_loss =0.0\n",
    "    train_acc=0.0\n",
    "    model = model.train()\n",
    "    \n",
    "    start = time.time()\n",
    "    for batch_num, lokacije in enumerate(loader):\n",
    "            #test_out()\n",
    "           # print(\"RADI\")\n",
    "            x=lokacije['data']\n",
    "            y=lokacije['label']\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "           # print(x)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x)\n",
    "            #print(y_hat.get_device())\n",
    "            #print(y.get_device())\n",
    "           # print(y_hat,totensor(y))\n",
    "            loss = loss_funk(y_hat, totensor(y))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            train_running_loss += loss.detach().item()\n",
    "            train_acc += get_accuracy(y_hat=y_hat, y=y)\n",
    "            del y_hat\n",
    "            del x\n",
    "            del y \n",
    "            del loss\n",
    "\n",
    "            print(f'Epoch: {epoha}\\t{100 * (batch_num + 1) / len(loader):.2f}% complete. {time.time() - start:.2f} seconds elapsed in epoch. Time until completion {(time.time()-start)/((batch_num + 1) / len(loader)) - time.time()+start:.2f} seconds.',\n",
    "                end='\\r')\n",
    "\n",
    "    print(f'',end='\\n')    \n",
    "    epoch_loss = train_running_loss / (batch_num+1)\n",
    "    epoch_acc = 100*train_acc / ((batch_num+1)*batch_velicina)\n",
    "    val_loss,val_acc = validation(model)\n",
    "    if val_acc>best_acc:\n",
    "        best_acc=val_acc\n",
    "        best_model=copy.deepcopy(model)\n",
    "        torch.save(best_model,'VGGBestModel.pt')\n",
    "        ouf.write(\"NEW BEST MODEL: \")\n",
    "        print(\"NEW BEST MODEL: \",end='')\n",
    "\n",
    "    ouf.write('Epoch: %d | Train Loss: %.4f | Train Accuracy: %.2f | Validation Loss: %.4f | Validation Accuracy: %.2f' \\\n",
    "          %(epoha, epoch_loss, epoch_acc,val_loss,val_acc))\n",
    "    ouf.write(\"\\n\")\n",
    "    print('Epoch: %d | Train Loss: %.4f | Train Accuracy: %.2f | Validation Loss: %.4f | Validation Accuracy: %.2f' \\\n",
    "          %(epoha, epoch_loss, epoch_acc,val_loss,val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(val_set)):\n",
    "    a=val_set[i]['data']\n",
    "    if(test(model,a)==val_set[i]['label']):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        kol=0\n",
    "        total_loss=0\n",
    "        for batch_num, lokacije in enumerate(val_loader):\n",
    "            x=lokacije['data']\n",
    "            y=lokacije['label']\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "                #print(y)\n",
    "            y_hat = model(x)\n",
    "            loss=loss_funk(y_hat,totensor(y))\n",
    "            total_loss+=loss.detach().item()\n",
    "           # print(np.argmax(y_hat.cpu().detach().numpy(),axis=1),y)\n",
    "            kol+=get_accuracy(y_hat=y_hat, y=y)/len(y)\n",
    "            #print(kol)\n",
    "            del y_hat\n",
    "        print(batch_num)\n",
    "        kol=kol*100/(batch_num+1)\n",
    "        #total_loss/=(batch_num+1)\n",
    "    return total_loss,kol\n",
    "\n",
    "validation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(dataset=val_set,batch_size=5,shuffle=False,num_workers=0,drop_last=False,pin_memory=True)\n",
    "\n",
    "def get_accuracy(y_hat,y):\n",
    "    y_hat = y_hat.cpu().detach().numpy()\n",
    "    y=y.cpu().numpy()\n",
    "    #print(y_hat)\n",
    "    y_hat=np.argmax(y_hat,axis=1)\n",
    "    #print(y_hat)\n",
    "    corrects=(y_hat==y).sum()\n",
    "    #print(y_hat,y,corrects)\n",
    "    return corrects.item()\n",
    "\n",
    "def vall(model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        kol=0\n",
    "        for batch_num, lokacije in enumerate(val_loader):\n",
    "            x=lokacije['data']\n",
    "            y=lokacije['label']\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "                #print(y)\n",
    "            #print(x.size())\n",
    "            y_hat = model(x)\n",
    "            #print(y_hat)\n",
    "            #print(y_hat,y)\n",
    "            kol+=get_accuracy(y_hat=y_hat, y=y)\n",
    "            del y_hat\n",
    "    return kol\n",
    "\n",
    "vall(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validation(best_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model,'VGGBestModel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = torch.load('VGGBestModel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
