{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ucitavamo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "\n",
    "\n",
    "ulaz= np.loadtxt('TrainDataset.txt')\n",
    "podaci=ulaz[:,1:]\n",
    "obelezja=ulaz[:,:1]\n",
    "obelezja=torch.Tensor(obelezja)\n",
    "obelezja=obelezja.flatten()\n",
    "\n",
    "ulaz= np.loadtxt('TestDataset.txt')\n",
    "tpodaci=ulaz[:,1:]\n",
    "tmp = np.concatenate((podaci,tpodaci))\n",
    "b=np.max(tmp,axis=0)\n",
    "podaci=podaci/b\n",
    "tpodaci=tpodaci/b\n",
    "tobelezja=ulaz[:,:1]\n",
    "tpodaci=torch.Tensor(tpodaci)\n",
    "tobelezja=torch.Tensor(tobelezja)\n",
    "tobelezja=tobelezja.flatten()\n",
    "\n",
    "\n",
    "podaci=torch.Tensor(podaci)\n",
    "\n",
    "test_set=TensorDataset(tpodaci,tobelezja)\n",
    "dataset=TensorDataset(podaci,obelezja)\n",
    "train_set,val_set = torch.utils.data.random_split(dataset,[0.9,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_set))\n",
    "print(len(val_set))\n",
    "print(len(test_set))\n",
    "print(len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=\"cuda\"\n",
    "else:\n",
    "    device=\"cpu\"\n",
    "    print(\"NE RADI CUDA!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicijalizacija mreze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Mreza (nn.Module):\n",
    "    def __init__ (self):\n",
    "        super().__init__()\n",
    "        self.act=nn.Sequential(\n",
    "            nn.Linear(1564,1000),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000,300),\n",
    "            nn.BatchNorm1d(300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300,120),\n",
    "            nn.BatchNorm1d(120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120,50),\n",
    "            nn.BatchNorm1d(50),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.act=self.act.to(device)\n",
    "    def forward (self, x):\n",
    "        return self.act(x)\n",
    "model = Mreza()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testiranje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def totensor(y):\n",
    "    ret=np.zeros((len(y),50))\n",
    "   # print(y[0])\n",
    "   # print(y[0][0])\n",
    "   # print(y[0][0].item())\n",
    "    for i in range(0,len(y)):\n",
    "        ret[i][round(y[i].item())]=1\n",
    "    return torch.Tensor(ret).to(device)\n",
    "\n",
    "def test(model,sample):\n",
    "    #print(sample)\n",
    "    sample=sample.to(device)\n",
    "    rez=model(sample.reshape(1,1564))\n",
    "    _,b=torch.max(rez,dim=1)\n",
    "    return b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicijalizacija parametara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broj_epoha = 15\n",
    "batch_velicina=500\n",
    "loss_funk = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "loader = torch.utils.data.DataLoader(dataset=train_set,batch_size=batch_velicina,shuffle=True,num_workers=0,drop_last=True,pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_set,batch_size=batch_velicina,shuffle=False,num_workers=0,drop_last=False,pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_hat,y):\n",
    "   # print(y)\n",
    "    y_hat = y_hat.cpu().detach().numpy()\n",
    "    y=y.cpu().numpy()\n",
    "    y_hat=np.argmax(y_hat,axis=1)\n",
    "   # print(y_hat,y)\n",
    "    corrects=(y_hat==y).sum()\n",
    "   # print(corrects)\n",
    "    return corrects.item()\n",
    "\n",
    "def validation(model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        kol=0\n",
    "        total_loss=0\n",
    "        for batch_num, (x, y) in enumerate(val_loader):\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                #print(y)\n",
    "                y_hat = model(x)\n",
    "                loss=loss_funk(y_hat,totensor(y))\n",
    "                total_loss+=loss.detach().item()\n",
    "                kol+=get_accuracy(y_hat=y_hat, y=y)/len(y)\n",
    "                del y_hat\n",
    "        kol=kol*100/batch_num\n",
    "        total_loss/=batch_num\n",
    "    return total_loss,kol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treniranje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE SURE TO INITIALIZE PARAMETERS BEFORE STARTING TRAINING\n",
    "best_model=model\n",
    "best_loss=100000000\n",
    "\n",
    "import copy\n",
    "import time\n",
    "for epoha in range(1,broj_epoha+1):\n",
    "    train_running_loss =0.0\n",
    "    train_acc=0.0\n",
    "    model = model.train() \n",
    "    start=time.time()\n",
    "    for batch_num, (x, y) in enumerate(loader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "           # print(y)\n",
    "            #print(y)\n",
    "            y_hat = model(x)\n",
    "            loss = loss_funk(y_hat, totensor(y))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            train_running_loss += loss.detach().item()\n",
    "            train_acc += get_accuracy(y_hat=y_hat, y=y)/len(y)\n",
    "            del y_hat\n",
    "\n",
    "            print(f'Epoch: {epoha}\\t{100 * (batch_num + 1) / len(loader):.2f}% complete. {time.time() - start:.2f} seconds elapsed in epoch. Time until completion {(time.time()-start)/((batch_num + 1) / len(loader)) - time.time()+start:.2f} seconds.',\n",
    "                end='\\r')\n",
    "\n",
    "    print(f'',end='\\n')    \n",
    "    epoch_loss = train_running_loss / batch_num\n",
    "    epoch_acc = 100*train_acc / batch_num\n",
    "    val_loss,val_acc = validation(model)\n",
    "    if val_loss<best_loss:\n",
    "          best_loss=val_loss\n",
    "          best_model=copy.deepcopy(model)\n",
    "    print('Epoch: %d | Train Loss: %.4f | Train Accuracy: %.2f | Validation Loss: %.4f | Validation Accuracy: %.2f' \\\n",
    "          %(epoha, epoch_loss, epoch_acc,val_loss,val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testt(model):\n",
    "        kol=0\n",
    "        for i in range(0,len(val_set)):\n",
    "            out=test(model,val_set[i][0].reshape(1,1564))\n",
    "            ans=val_set[i][1].item()\n",
    "            if round(ans)==out:\n",
    "                kol+=1\n",
    "        return kol\n",
    "print(testt(model))\n",
    "print(testt(model)/len(val_set)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_loss)\n",
    "print(validation(best_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "ulaz= np.loadtxt('TestDataset.txt')\n",
    "podaci=ulaz[:,1:]\n",
    "#print(podaci)\n",
    "b=np.max(podaci,axis=0)\n",
    "podaci=podaci/b\n",
    "#print(podaci)\n",
    "#print(np.max(podaci),np.min(podaci))\n",
    "obelezja=ulaz[:,:1]\n",
    "#print(obelezja)\n",
    "podaci=torch.Tensor(podaci)\n",
    "obelezja=torch.Tensor(obelezja)\n",
    "obelezja=obelezja.flatten()\n",
    "\n",
    "test_set=TensorDataset(podaci,obelezja)\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouf = open(\"Rezultati.txt\")\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    kol=0\n",
    "    for i in range(0,len(test_set)):\n",
    "        if(test_set[i][1].cpu().item()==test(model,test_set[i][0]).cpu().item()):\n",
    "            kol+=1\n",
    "    print(kol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
